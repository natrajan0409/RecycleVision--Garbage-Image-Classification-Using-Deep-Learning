{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "095064aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import time\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6ae5f4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device Set is cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device Set is {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a180bc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './data'\n",
    "MODEL_PATH = './simple_cifar10.pth'\n",
    "BATCH_SIZE = 32\n",
    "EPOCH = 10\n",
    "LR = 1e-3\n",
    "NUM_CLASSES = 10\n",
    "MODEL_PATH = '/mnt/tmp/simple_cfar10.pth'\n",
    "CLASSES = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "MEAN = (0.4194,0.4852,0.4465)\n",
    "STD = (0.2470,0.2435,0.2616)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "986da4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples:50000\n",
      "Test Samples :10000\n",
      "Image Shape : torch.Size([3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "raw = torchvision.datasets.CIFAR10(root=DATA_DIR, train=True, download=True, transform=T.ToTensor())\n",
    "test_raw = torchvision.datasets.CIFAR10(root=DATA_DIR, train=False, download=True, transform=T.ToTensor())\n",
    "\n",
    "img, lbl = raw[0]\n",
    "print(f\"Train samples:{len(raw)}\")\n",
    "print(f\"Test Samples :{len(test_raw)}\")\n",
    "print(f\"Image Shape : {img.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "10eebbec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frog : 5000\n",
      "truck : 5000\n",
      "deer : 5000\n",
      "automobile : 5000\n",
      "bird : 5000\n",
      "horse : 5000\n",
      "ship : 5000\n",
      "cat : 5000\n",
      "dog : 5000\n",
      "airplane : 5000\n"
     ]
    }
   ],
   "source": [
    "counts = Counter(raw.targets)\n",
    "for k,v in counts.items():\n",
    "    print(f\"{CLASSES[k]} : {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d510ad21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Batches : 1563\n",
      "Val Batches : 313\n",
      "Train Batch Shape : (32, 3, 32, 32)\n",
      "  RandomCrop(size=(32, 32), padding=4)\n",
      "  RandomHorizontalFlip(p=0.5)\n",
      "  ColorJitter(brightness=(0.8, 1.2), contrast=(0.8, 1.2), saturation=(0.8, 1.2), hue=(-0.05, 0.05))\n",
      "  RandomRotation(degrees=[-10.0, 10.0], interpolation=nearest, expand=False, fill=0)\n",
      "  ToTensor()\n",
      "  Normalize(mean=(0.4194, 0.4852, 0.4465), std=(0.247, 0.2435, 0.2616))\n",
      "  RandomErasing(p=0.15, scale=(0.02, 0.2), ratio=(0.3, 3.3), value=0, inplace=False)\n"
     ]
    }
   ],
   "source": [
    "train_tfm = T.Compose([\n",
    "      T.RandomCrop(32, padding=4, padding_mode=\"reflect\"),\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.05),\n",
    "    T.RandomRotation(10),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(MEAN, STD),\n",
    "    T.RandomErasing(p=0.15, scale=(0.02, 0.2)),\n",
    "])\n",
    "\n",
    "val_tfm = T.Compose([\n",
    "        T.ToTensor(),\n",
    "    T.Normalize(MEAN, STD),\n",
    "])\n",
    "\n",
    "train_ds = torchvision.datasets.CIFAR10(root=DATA_DIR, train=True, download=True, transform=train_tfm)\n",
    "val_ds = torchvision.datasets.CIFAR10(root=DATA_DIR, train=False, download=True, transform=val_tfm)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "\n",
    "imgs, lbls = next(iter(train_loader))\n",
    "\n",
    "print(f\"Train Batches : {len(train_loader)}\")\n",
    "print(f\"Val Batches : {len(val_loader)}\")\n",
    "print(f\"Train Batch Shape : {tuple(imgs.shape)}\")\n",
    "\n",
    "\n",
    "for t in train_tfm.transforms:\n",
    "  print(f\"  {t}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dc9613bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple CNN Architecure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "42d5cb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Custom CNN for CIFAR-10  (32×32 RGB → 10 classes)\n",
    "    ──────────────────────────────────────────────────\n",
    "    Input → Block1 → Block2 → Block3 → Classifier\n",
    "\n",
    "    Each block:\n",
    "        Conv2d → BatchNorm → ReLU → Conv2d → BatchNorm → ReLU → MaxPool → Dropout\n",
    "\n",
    "    Classifier:\n",
    "        Flatten → FC(512) → BN → ReLU → Dropout → FC(10)\n",
    "    ──────────────────────────────────────────────────\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes: int = 10):\n",
    "        super().__init__()\n",
    "\n",
    "        # ── Block 1:  3 → 32 channels  |  32×32 → 16×16 ──────────\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(3,  32, kernel_size=3, padding=1, bias=False),  # 32×32\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1, bias=False),  # 32×32\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),                                        # 16×16\n",
    "            nn.Dropout2d(p=0.2),\n",
    "        )\n",
    "\n",
    "        # ── Block 2: 32 → 64 channels  |  16×16 → 8×8 ────────────\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1, bias=False),  # 16×16\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1, bias=False),  # 16×16\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),                                        # 8×8\n",
    "            nn.Dropout2d(p=0.3),\n",
    "        )\n",
    "\n",
    "        # ── Block 3: 64 → 128 channels  |  8×8 → 4×4 ─────────────\n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1, bias=False), # 8×8\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1, bias=False),# 8×8\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),                                        # 4×4\n",
    "            nn.Dropout2d(p=0.4),\n",
    "        )\n",
    "\n",
    "        # ── Classifier head ───────────────────────────────────────\n",
    "        # After block3: (B, 128, 4, 4) → flatten → 128*4*4 = 2048\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 4 * 4, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(512, num_classes),\n",
    "        )\n",
    "\n",
    "        # ── Weight init (Kaiming He) ──────────────────────────────\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out',\n",
    "                                        nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.BatchNorm1d)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias,   0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.block1(x)       # (B,  3, 32, 32) → (B,  32, 16, 16)\n",
    "        x = self.block2(x)       # (B, 32, 16, 16) → (B,  64,  8,  8)\n",
    "        x = self.block3(x)       # (B, 64,  8,  8) → (B, 128,  4,  4)\n",
    "        x = self.classifier(x)   # → (B, 10)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0179793d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleCNN(\n",
      "  (block1): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Dropout2d(p=0.2, inplace=False)\n",
      "  )\n",
      "  (block2): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Dropout2d(p=0.3, inplace=False)\n",
      "  )\n",
      "  (block3): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Dropout2d(p=0.4, inplace=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=2048, out_features=512, bias=True)\n",
      "    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Dropout(p=0.5, inplace=False)\n",
      "    (5): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = SimpleCNN(num_classes=NUM_CLASSES).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "19fff5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params : {1342698}\n",
      "Trainable Params : {1342698}\n"
     ]
    }
   ],
   "source": [
    "total_p = { sum(p.numel() for p in model.parameters()) }\n",
    "train_p = { sum(p.numel() for p in model.parameters() if p.requires_grad) }\n",
    "print(f\"Total Params : {total_p}\")\n",
    "print(f\"Trainable Params : {train_p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b87b6632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training utilities\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a105e7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    loss_sum , correct , total = 0.0 , 0 , 0\n",
    "    for img,lables in train_loader:\n",
    "        img,lables = img.to(device) , lables.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(img)\n",
    "        loss = criterion(output,lables)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_sum += loss.item()\n",
    "        correct += (output.argmax(1) == lables).sum().item()\n",
    "        total += lables.size(0)\n",
    "    return loss_sum/total , correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4458a1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    loss_sum , correct , total = 0.0 , 0 , 0\n",
    "    for img,lables in val_loader:\n",
    "        img,lables = img.to(device) , lables.to(device)\n",
    "        output = model(img)\n",
    "        loss = criterion(output,lables)\n",
    "        loss_sum += loss.item()\n",
    "        correct += (output.argmax(1) == lables).sum().item()\n",
    "        total += lables.size(0)\n",
    "    return loss_sum / len(val_loader) , correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6cf44fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = './simple_cifar10.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "df7a622e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch   Tr Loss    Tr Acc   Va Loss    Va Acc         LR    Time\n",
      "     1    0.0602     0.31%    1.3490     0.50%   56.6s\n",
      "     2    0.0479     0.44%    1.1134     0.59%   55.4s\n",
      "     3    0.0425     0.51%    0.9421     0.67%   53.3s\n",
      "     4    0.0393     0.55%    0.8897     0.69%   50.5s\n",
      "     5    0.0370     0.58%    0.8216     0.71%   49.7s\n",
      "     6    0.0354     0.60%    0.7783     0.72%   51.2s\n",
      "     7    0.0341     0.61%    0.7354     0.75%   51.7s\n",
      "     8    0.0330     0.63%    0.7015     0.76%   50.7s\n",
      "     9    0.0322     0.64%    0.6692     0.77%   51.1s\n",
      "    10    0.0313     0.65%    0.6402     0.79%   50.9s\n"
     ]
    }
   ],
   "source": [
    "history = dict(train_loss=[], train_acc=[], val_loss=[], val_acc=[])\n",
    "best_acc = 0.0\n",
    "print(f\"\\n{'Epoch':>6}  {'Tr Loss':>8}  {'Tr Acc':>8}  \"\n",
    "      f\"{'Va Loss':>8}  {'Va Acc':>8}  {'LR':>9}  {'Time':>6}\")\n",
    "for epoch in range(1,EPOCH + 1):\n",
    "  t0 = time.time()\n",
    "  tr_loss , tr_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "  va_loss , va_acc = evaluate(model, val_loader,criterion,device)\n",
    "  history['train_loss'] = tr_loss\n",
    "  history['train_acc'] = tr_acc\n",
    "  history['val_loss'] = va_loss\n",
    "  history['val_acc'] = va_acc\n",
    "\n",
    "  if va_acc > best_acc:\n",
    "    best_acc = va_acc\n",
    "    torch.save({\"Epoch\": epoch, \"State\": model.state_dict(), \"Val_acc\": va_acc},MODEL_PATH )\n",
    "\n",
    "  print(f\"{epoch:>6}  {tr_loss:>8.4f}  {tr_acc:>7.2f}%  \"\n",
    "          f\"{va_loss:>8.4f}  {va_acc:>7.2f}%  \"\n",
    "          f\"{time.time()-t0:>5.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b1295591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================================================\n",
      "  1. DATASET — CIFAR-10\n",
      "==============================================================\n",
      "Train samples   :  50,000\n",
      "Test  samples   :  10,000\n",
      "Image shape     :  (3, 32, 32)   (C x H x W)\n",
      "Classes (10)     :  ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "Device          :  cuda\n",
      "\n",
      "Class distribution:\n",
      "  0  plane    5,000  =========================\n",
      "  1  car      5,000  =========================\n",
      "  2  bird     5,000  =========================\n",
      "  3  cat      5,000  =========================\n",
      "  4  deer     5,000  =========================\n",
      "  5  dog      5,000  =========================\n",
      "  6  frog     5,000  =========================\n",
      "  7  horse    5,000  =========================\n",
      "  8  ship     5,000  =========================\n",
      "  9  truck    5,000  =========================\n",
      "\n",
      "==============================================================\n",
      "  2. DATA AUGMENTATION & DATALOADERS\n",
      "==============================================================\n",
      "Train batches  :  782\n",
      "Val   batches  :  157\n",
      "Batch shape    :  (64, 3, 32, 32)\n",
      "\n",
      "==============================================================\n",
      "  3. SIMPLE CNN ARCHITECTURE\n",
      "==============================================================\n",
      "SimpleCNN(\n",
      "  (block1): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Dropout2d(p=0.2, inplace=False)\n",
      "  )\n",
      "  (block2): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Dropout2d(p=0.3, inplace=False)\n",
      "  )\n",
      "  (block3): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Dropout2d(p=0.4, inplace=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=2048, out_features=512, bias=True)\n",
      "    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Dropout(p=0.5, inplace=False)\n",
      "    (5): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Total parameters     :  1,342,698\n",
      "Trainable parameters :  1,342,698\n",
      "Model size (FP32)    :  5.37 MB\n",
      "\n",
      "==============================================================\n",
      "  4. TRAINING LOOP\n",
      "==============================================================\n",
      "\n",
      " Epoch   Tr Loss    Tr Acc   Va Loss    Va Acc         LR    Time\n",
      "------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\workspace\\GUVI_Recycle\\venv_cuda\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1       nan    28.64%       nan    10.00%   0.005205   55.5s *\n",
      "     2       nan    41.80%       nan    10.00%   0.010000   55.2s\n",
      "     3       nan    48.62%       nan    10.00%   0.009618   53.4s\n",
      "     4       nan    52.25%       nan    10.00%   0.008534   53.9s\n",
      "     5       nan    54.15%       nan    10.00%   0.006911   54.0s\n",
      "     6       nan    56.70%       nan    10.00%   0.004998   52.6s\n",
      "     7       nan    59.37%       nan    10.00%   0.003084   52.9s\n",
      "     8       nan    62.94%       nan    10.00%   0.001463   53.0s\n",
      "     9       nan    66.35%       nan    10.00%   0.000380   53.9s\n",
      "    10       nan    68.51%       nan    10.00%   0.000000   54.0s\n",
      "\n",
      "Best validation accuracy :  10.00%\n",
      "\n",
      "==============================================================\n",
      "  5. PER-CLASS ACCURACY\n",
      "==============================================================\n",
      "\n",
      "Class      Correct   Total       Acc   Bar\n",
      "-------------------------------------------------------\n",
      "plane         1000    1000   100.00%   ====================\n",
      "car              0    1000     0.00%   \n",
      "bird             0    1000     0.00%   \n",
      "cat              0    1000     0.00%   \n",
      "deer             0    1000     0.00%   \n",
      "dog              0    1000     0.00%   \n",
      "frog             0    1000     0.00%   \n",
      "horse            0    1000     0.00%   \n",
      "ship             0    1000     0.00%   \n",
      "truck            0    1000     0.00%   \n",
      "\n",
      "==============================================================\n",
      "  6. CONFUSION MATRIX  (rows=true, cols=predicted)\n",
      "==============================================================\n",
      "        plane   car  bird   cat  deer   dog  frog horse  ship truck\n",
      "  plane[1000]    0     0     0     0     0     0     0     0     0 \n",
      "    car 1000 [  0]    0     0     0     0     0     0     0     0 \n",
      "   bird 1000     0 [  0]    0     0     0     0     0     0     0 \n",
      "    cat 1000     0     0 [  0]    0     0     0     0     0     0 \n",
      "   deer 1000     0     0     0 [  0]    0     0     0     0     0 \n",
      "    dog 1000     0     0     0     0 [  0]    0     0     0     0 \n",
      "   frog 1000     0     0     0     0     0 [  0]    0     0     0 \n",
      "  horse 1000     0     0     0     0     0     0 [  0]    0     0 \n",
      "   ship 1000     0     0     0     0     0     0     0 [  0]    0 \n",
      "  truck 1000     0     0     0     0     0     0     0     0 [  0]\n",
      "\n",
      "==============================================================\n",
      "  7. SINGLE IMAGE INFERENCE  (first 10 test images)\n",
      "==============================================================\n",
      "\n",
      "  #      True   Predicted   Confidence  Result\n",
      "------------------------------------------------\n",
      "  1       cat       plane         nan%   X\n",
      "  2      ship       plane         nan%   X\n",
      "  3      ship       plane         nan%   X\n",
      "  4     plane       plane         nan%   OK\n",
      "  5      frog       plane         nan%   X\n",
      "  6      frog       plane         nan%   X\n",
      "  7       car       plane         nan%   X\n",
      "  8      frog       plane         nan%   X\n",
      "  9       cat       plane         nan%   X\n",
      " 10       car       plane         nan%   X\n",
      "\n",
      "==============================================================\n",
      "  8. TRAINING HISTORY\n",
      "==============================================================\n",
      "\n",
      "  Ep   Train Acc     Val Acc  Progress\n",
      "-------------------------------------------------------\n",
      "   1      28.64%      10.00%  ==\n",
      "   2      41.80%      10.00%  ==\n",
      "   3      48.62%      10.00%  ==\n",
      "   4      52.25%      10.00%  ==\n",
      "   5      54.15%      10.00%  ==\n",
      "   6      56.70%      10.00%  ==\n",
      "   7      59.37%      10.00%  ==\n",
      "   8      62.94%      10.00%  ==\n",
      "   9      66.35%      10.00%  ==\n",
      "  10      68.51%      10.00%  ==\n",
      "\n",
      "Final  train acc  :  68.51%\n",
      "Final  val   acc  :  10.00%\n",
      "Best   val   acc  :  10.00%\n",
      "Overfit gap       :  58.51%\n",
      "\n",
      "==============================================================\n",
      "  9. SAVE & RELOAD BEST CHECKPOINT\n",
      "==============================================================\n",
      "Saved at epoch    :  1\n",
      "Saved val acc     :  10.00%\n",
      "Reloaded val acc  :  10.00%  OK\n",
      "\n",
      "==============================================================\n",
      "  ARCHITECTURE SUMMARY\n",
      "==============================================================\n",
      "\n",
      "Stage            Layers                                 Output       Params\n",
      "------------------------------------------------------------------------------\n",
      "Input            —                                      3x32x32      —\n",
      "Block 1          Conv(3->32) BN ReLU x2 MaxPool         32x16x16     ~18K\n",
      "Block 2          Conv(32->64) BN ReLU x2 MaxPool        64x8x8       ~74K\n",
      "Block 3          Conv(64->128) BN ReLU x2 MaxPool       128x4x4      ~295K\n",
      "Flatten          —                                      2048         —\n",
      "FC(2048->512)    Linear BN ReLU Dropout(0.5)            512          ~1.0M\n",
      "FC(512->10)      Linear                                 10           ~5K\n",
      "\n",
      "Total trainable parameters :  1,342,698  (~1.34 M)\n",
      "\n",
      "==============================================================\n",
      "  Simple CNN + CIFAR-10 complete\n",
      "==============================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Simple CNN on CIFAR-10  —  Built from Scratch (No Pretrained Weights)\n",
    "======================================================================\n",
    "Architecture  :  Custom 3-block CNN\n",
    "Dataset       :  CIFAR-10  (60 000 RGB 32x32 images, 10 classes)\n",
    "Framework     :  PyTorch\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import time\n",
    "from collections import Counter\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────\n",
    "# CONFIG\n",
    "# ──────────────────────────────────────────────────────────────────\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "DATA_DIR    = \"./data\"\n",
    "BATCH_SIZE  = 64\n",
    "EPOCHS      = 10\n",
    "LR          = 1e-3\n",
    "NUM_CLASSES = 10\n",
    "CKPT_PATH   = \"./simple_cnn_cifar10.pth\"\n",
    "\n",
    "CLASSES = [\"plane\",\"car\",\"bird\",\"cat\",\"deer\",\n",
    "           \"dog\",\"frog\",\"horse\",\"ship\",\"truck\"]\n",
    "\n",
    "MEAN = (0.4914, 0.4822, 0.4465)\n",
    "STD  = (0.2470, 0.2435, 0.2616)\n",
    "\n",
    "sep = lambda t: print(f\"\\n{'='*62}\\n  {t}\\n{'='*62}\")\n",
    "\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "# MODEL DEFINITION  (must be importable at module level on Windows)\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "class SimpleCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Custom CNN for CIFAR-10  (32x32 RGB -> 10 classes)\n",
    "    Input -> Block1 -> Block2 -> Block3 -> Classifier\n",
    "    Each block: Conv->BN->ReLU->Conv->BN->ReLU->MaxPool->Dropout\n",
    "    Classifier: Flatten->FC(512)->BN->ReLU->Dropout->FC(10)\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes: int = 10):\n",
    "        super().__init__()\n",
    "\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(3,  32, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(32), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(32), nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2), nn.Dropout2d(p=0.2),\n",
    "        )\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64), nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2), nn.Dropout2d(p=0.3),\n",
    "        )\n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.Conv2d(64,  128, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(128), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(128), nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2), nn.Dropout2d(p=0.4),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 4 * 4, 512),\n",
    "            nn.BatchNorm1d(512), nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(512, num_classes),\n",
    "        )\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.BatchNorm1d)):\n",
    "                nn.init.constant_(m.weight, 1); nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight); nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        return self.classifier(x)\n",
    "\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "# TRAINING UTILITIES  (defined at module level — importable)\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "def train_epoch(model, loader, criterion, optimizer, scaler, scheduler=None):\n",
    "    model.train()\n",
    "    loss_sum, correct, total = 0.0, 0, 0\n",
    "    for imgs, labels in loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with torch.amp.autocast(device_type=device.type,\n",
    "                                 enabled=(device.type == \"cuda\")):\n",
    "            out  = model(imgs)\n",
    "            loss = criterion(out, labels)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()   # OneCycleLR steps once per BATCH\n",
    "        loss_sum += loss.item() * imgs.size(0)\n",
    "        correct  += (out.argmax(1) == labels).sum().item()\n",
    "        total    += imgs.size(0)\n",
    "    return loss_sum / total, 100.0 * correct / total\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    loss_sum, correct, total = 0.0, 0, 0\n",
    "    all_preds, all_labels = [], []\n",
    "    for imgs, labels in loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        out   = model(imgs)\n",
    "        loss  = criterion(out, labels)\n",
    "        preds = out.argmax(1)\n",
    "        loss_sum += loss.item() * imgs.size(0)\n",
    "        correct  += (preds == labels).sum().item()\n",
    "        total    += imgs.size(0)\n",
    "        all_preds.append(preds.cpu())\n",
    "        all_labels.append(labels.cpu())\n",
    "    return (loss_sum / total,\n",
    "            100.0 * correct / total,\n",
    "            torch.cat(all_preds),\n",
    "            torch.cat(all_labels))\n",
    "\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "# MAIN — required on Windows for multiprocessing in DataLoader\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # ── 1. Dataset download & exploration ────────────────────────\n",
    "    sep(\"1. DATASET — CIFAR-10\")\n",
    "\n",
    "    raw      = torchvision.datasets.CIFAR10(root=DATA_DIR, train=True,\n",
    "                                             download=True, transform=T.ToTensor())\n",
    "    test_raw = torchvision.datasets.CIFAR10(root=DATA_DIR, train=False,\n",
    "                                             download=True, transform=T.ToTensor())\n",
    "    img0, lbl0 = raw[0]\n",
    "    print(f\"Train samples   :  {len(raw):,}\")\n",
    "    print(f\"Test  samples   :  {len(test_raw):,}\")\n",
    "    print(f\"Image shape     :  {tuple(img0.shape)}   (C x H x W)\")\n",
    "    print(f\"Classes ({NUM_CLASSES})     :  {CLASSES}\")\n",
    "    print(f\"Device          :  {device}\")\n",
    "\n",
    "    print(\"\\nClass distribution:\")\n",
    "    counts = Counter(raw.targets)\n",
    "    for i, cls in enumerate(CLASSES):\n",
    "        bar = \"=\" * (counts[i] // 200)\n",
    "        print(f\"  {i}  {cls:<7}  {counts[i]:,}  {bar}\")\n",
    "\n",
    "    # ── 2. DataLoaders ───────────────────────────────────────────\n",
    "    sep(\"2. DATA AUGMENTATION & DATALOADERS\")\n",
    "\n",
    "    train_tfm = T.Compose([\n",
    "        T.RandomCrop(32, padding=4, padding_mode=\"reflect\"),\n",
    "        T.RandomHorizontalFlip(p=0.5),\n",
    "        T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.05),\n",
    "        T.RandomRotation(10),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(MEAN, STD),\n",
    "        T.RandomErasing(p=0.15, scale=(0.02, 0.2)),\n",
    "    ])\n",
    "    val_tfm = T.Compose([T.ToTensor(), T.Normalize(MEAN, STD)])\n",
    "\n",
    "    train_ds = torchvision.datasets.CIFAR10(root=DATA_DIR, train=True,\n",
    "                                             download=False, transform=train_tfm)\n",
    "    val_ds   = torchvision.datasets.CIFAR10(root=DATA_DIR, train=False,\n",
    "                                             download=False, transform=val_tfm)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True,  num_workers=2, pin_memory=True)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE,\n",
    "                              shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "    imgs, lbls = next(iter(train_loader))\n",
    "    print(f\"Train batches  :  {len(train_loader)}\")\n",
    "    print(f\"Val   batches  :  {len(val_loader)}\")\n",
    "    print(f\"Batch shape    :  {tuple(imgs.shape)}\")\n",
    "\n",
    "    # ── 3. Model ─────────────────────────────────────────────────\n",
    "    sep(\"3. SIMPLE CNN ARCHITECTURE\")\n",
    "\n",
    "    model       = SimpleCNN(num_classes=NUM_CLASSES).to(device)\n",
    "    total_p     = sum(p.numel() for p in model.parameters())\n",
    "    trainable_p = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(model)\n",
    "    print(f\"\\nTotal parameters     :  {total_p:,}\")\n",
    "    print(f\"Trainable parameters :  {trainable_p:,}\")\n",
    "    print(f\"Model size (FP32)    :  {total_p * 4 / 1e6:.2f} MB\")\n",
    "\n",
    "    # ── 4. Training setup ────────────────────────────────────────\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LR, weight_decay=1e-4)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer, max_lr=LR * 10,\n",
    "        epochs=EPOCHS, steps_per_epoch=len(train_loader),\n",
    "        pct_start=0.2, anneal_strategy=\"cos\",\n",
    "    )\n",
    "    scaler = torch.amp.GradScaler(device.type, enabled=(device.type == \"cuda\"))\n",
    "\n",
    "    # ── 5. Training loop ─────────────────────────────────────────\n",
    "    sep(\"4. TRAINING LOOP\")\n",
    "\n",
    "    history  = dict(tr_loss=[], tr_acc=[], va_loss=[], va_acc=[])\n",
    "    best_acc = 0.0\n",
    "\n",
    "    print(f\"\\n{'Epoch':>6}  {'Tr Loss':>8}  {'Tr Acc':>8}  \"\n",
    "          f\"{'Va Loss':>8}  {'Va Acc':>8}  {'LR':>9}  {'Time':>6}\")\n",
    "    print(\"-\" * 66)\n",
    "\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        t0 = time.time()\n",
    "        tr_loss, tr_acc       = train_epoch(model, train_loader,\n",
    "                                            criterion, optimizer, scaler, scheduler)\n",
    "        va_loss, va_acc, _, _ = evaluate(model, val_loader, criterion)\n",
    "\n",
    "        history[\"tr_loss\"].append(tr_loss)\n",
    "        history[\"tr_acc\"].append(tr_acc)\n",
    "        history[\"va_loss\"].append(va_loss)\n",
    "        history[\"va_acc\"].append(va_acc)\n",
    "\n",
    "        flag = \" *\" if va_acc > best_acc else \"\"\n",
    "        if va_acc > best_acc:\n",
    "            best_acc = va_acc\n",
    "            torch.save({\"epoch\": epoch, \"state\": model.state_dict(),\n",
    "                        \"val_acc\": va_acc}, CKPT_PATH)\n",
    "\n",
    "        lr_now = optimizer.param_groups[0][\"lr\"]\n",
    "        print(f\"{epoch:>6}  {tr_loss:>8.4f}  {tr_acc:>7.2f}%  \"\n",
    "              f\"{va_loss:>8.4f}  {va_acc:>7.2f}%  \"\n",
    "              f\"{lr_now:>9.6f}  {time.time()-t0:>5.1f}s{flag}\")\n",
    "\n",
    "    print(f\"\\nBest validation accuracy :  {best_acc:.2f}%\")\n",
    "\n",
    "    # ── 6. Per-class accuracy ─────────────────────────────────────\n",
    "    sep(\"5. PER-CLASS ACCURACY\")\n",
    "\n",
    "    _, _, all_preds, all_labels = evaluate(model, val_loader, criterion)\n",
    "    cls_correct = torch.zeros(NUM_CLASSES)\n",
    "    cls_total   = torch.zeros(NUM_CLASSES)\n",
    "    for p, l in zip(all_preds, all_labels):\n",
    "        cls_correct[l] += (p == l).item()\n",
    "        cls_total[l]   += 1\n",
    "\n",
    "    print(f\"\\n{'Class':<8}  {'Correct':>8}  {'Total':>6}  {'Acc':>8}   Bar\")\n",
    "    print(\"-\" * 55)\n",
    "    for i, cls in enumerate(CLASSES):\n",
    "        acc = 100.0 * cls_correct[i] / cls_total[i]\n",
    "        bar = \"=\" * int(acc / 5)\n",
    "        print(f\"{cls:<8}  {int(cls_correct[i]):>8}  \"\n",
    "              f\"{int(cls_total[i]):>6}  {acc:>7.2f}%   {bar}\")\n",
    "\n",
    "    # ── 7. Confusion matrix ───────────────────────────────────────\n",
    "    sep(\"6. CONFUSION MATRIX  (rows=true, cols=predicted)\")\n",
    "\n",
    "    conf = torch.zeros(NUM_CLASSES, NUM_CLASSES, dtype=torch.long)\n",
    "    for p, l in zip(all_preds, all_labels):\n",
    "        conf[l][p] += 1\n",
    "\n",
    "    print(f\"{'':>7}\" + \"\".join(f\"{c[:5]:>6}\" for c in CLASSES))\n",
    "    for i, cls in enumerate(CLASSES):\n",
    "        row = f\"{cls[:6]:>7}\"\n",
    "        for j in range(NUM_CLASSES):\n",
    "            v = conf[i][j].item()\n",
    "            row += f\"[{v:>3}]\" if i == j else f\" {v:>4} \"\n",
    "        print(row)\n",
    "\n",
    "    # ── 8. Single-image inference ─────────────────────────────────\n",
    "    sep(\"7. SINGLE IMAGE INFERENCE  (first 10 test images)\")\n",
    "\n",
    "    model.eval()\n",
    "    print(f\"\\n{'#':>3}  {'True':>8}  {'Predicted':>10}  {'Confidence':>11}  Result\")\n",
    "    print(\"-\" * 48)\n",
    "    with torch.no_grad():\n",
    "        for i in range(10):\n",
    "            img_t, true_lbl = val_ds[i]\n",
    "            logits = model(img_t.unsqueeze(0).to(device))\n",
    "            probs  = F.softmax(logits, dim=1).squeeze()\n",
    "            pred   = probs.argmax().item()\n",
    "            conf_p = probs[pred].item() * 100\n",
    "            symbol = \"OK\" if pred == true_lbl else \"X\"\n",
    "            print(f\"{i+1:>3}  {CLASSES[true_lbl]:>8}  \"\n",
    "                  f\"{CLASSES[pred]:>10}  {conf_p:>10.2f}%   {symbol}\")\n",
    "\n",
    "    # ── 9. Training history ───────────────────────────────────────\n",
    "    sep(\"8. TRAINING HISTORY\")\n",
    "\n",
    "    print(f\"\\n{'Ep':>4}  {'Train Acc':>10}  {'Val Acc':>10}  Progress\")\n",
    "    print(\"-\" * 55)\n",
    "    for ep, (tr, va) in enumerate(zip(history[\"tr_acc\"], history[\"va_acc\"]), 1):\n",
    "        bar = \"=\" * int(va / 5)\n",
    "        print(f\"{ep:>4}  {tr:>9.2f}%  {va:>9.2f}%  {bar}\")\n",
    "\n",
    "    print(f\"\\nFinal  train acc  :  {history['tr_acc'][-1]:.2f}%\")\n",
    "    print(f\"Final  val   acc  :  {history['va_acc'][-1]:.2f}%\")\n",
    "    print(f\"Best   val   acc  :  {best_acc:.2f}%\")\n",
    "    print(f\"Overfit gap       :  \"\n",
    "          f\"{history['tr_acc'][-1] - history['va_acc'][-1]:.2f}%\")\n",
    "\n",
    "    # ── 10. Save & reload ─────────────────────────────────────────\n",
    "    sep(\"9. SAVE & RELOAD BEST CHECKPOINT\")\n",
    "\n",
    "    ckpt   = torch.load(CKPT_PATH, map_location=device)\n",
    "    model2 = SimpleCNN(num_classes=NUM_CLASSES).to(device)\n",
    "    model2.load_state_dict(ckpt[\"state\"])\n",
    "    model2.eval()\n",
    "\n",
    "    _, reload_acc, _, _ = evaluate(model2, val_loader, criterion)\n",
    "    print(f\"Saved at epoch    :  {ckpt['epoch']}\")\n",
    "    print(f\"Saved val acc     :  {ckpt['val_acc']:.2f}%\")\n",
    "    print(f\"Reloaded val acc  :  {reload_acc:.2f}%  OK\")\n",
    "\n",
    "    # ── 11. Architecture summary ──────────────────────────────────\n",
    "    sep(\"ARCHITECTURE SUMMARY\")\n",
    "\n",
    "    summary = [\n",
    "        (\"Input\",        \"—\",                                \"3x32x32\",   \"—\"),\n",
    "        (\"Block 1\",      \"Conv(3->32) BN ReLU x2 MaxPool\",  \"32x16x16\",  \"~18K\"),\n",
    "        (\"Block 2\",      \"Conv(32->64) BN ReLU x2 MaxPool\", \"64x8x8\",    \"~74K\"),\n",
    "        (\"Block 3\",      \"Conv(64->128) BN ReLU x2 MaxPool\",\"128x4x4\",   \"~295K\"),\n",
    "        (\"Flatten\",      \"—\",                                \"2048\",      \"—\"),\n",
    "        (\"FC(2048->512)\",\"Linear BN ReLU Dropout(0.5)\",      \"512\",       \"~1.0M\"),\n",
    "        (\"FC(512->10)\",  \"Linear\",                           \"10\",        \"~5K\"),\n",
    "    ]\n",
    "    print(f\"\\n{'Stage':<16} {'Layers':<38} {'Output':<12} {'Params'}\")\n",
    "    print(\"-\" * 78)\n",
    "    for stage, layers, out, params in summary:\n",
    "        print(f\"{stage:<16} {layers:<38} {out:<12} {params}\")\n",
    "\n",
    "    print(f\"\\nTotal trainable parameters :  {trainable_p:,}  \"\n",
    "          f\"(~{trainable_p/1e6:.2f} M)\")\n",
    "    print(\"\\n\" + \"=\" * 62)\n",
    "    print(\"  Simple CNN + CIFAR-10 complete\")\n",
    "    print(\"=\" * 62)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
